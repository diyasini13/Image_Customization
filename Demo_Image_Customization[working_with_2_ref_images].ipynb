{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "1EcMsXpD9Og9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imagen 3 Image Generation\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/diyasini13/Image_Customization/blob/main/Demo_Image_Customization%5Bworking_with_2_ref_images%5D.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  \n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/diyasini13/Image_Customization/blob/main/Demo_Image_Customization%5Bworking_with_2_ref_images%5D.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n"
      ],
      "metadata": {
        "id": "hz11kiu5-y5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get started\n"
      ],
      "metadata": {
        "id": "dsQOWsrS-Csa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Vertex AI SDK for Python\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "peDrS9f3-H0j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "id": "FitxM8maceKs",
        "outputId": "2a7fdf1c-20ee-4942-e0d3-c7cd3444a3c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.11/dist-packages (1.74.0)\n",
            "Collecting google-cloud-aiplatform\n",
            "  Downloading google_cloud_aiplatform-1.78.0-py2.py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.19.2)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.25.5)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (24.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (1.14.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.0.6)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (2.10.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (4.12.2)\n",
            "Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform) (0.16)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.69.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.14.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->google-cloud-aiplatform) (2.27.2)\n",
            "Requirement already satisfied: numpy<3,>=1.14 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.12.14)\n",
            "Downloading google_cloud_aiplatform-1.78.0-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-cloud-aiplatform\n",
            "\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed google-cloud-aiplatform-1.78.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6b7485d9dbec440daf0bd8dc4296554b",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%pip install --upgrade --user google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
        "\n",
        "The restart might take a minute or longer. After it's restarted, continue to the next step."
      ],
      "metadata": {
        "id": "yqG_ooJJ-L7j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCOWtR7Gcja1",
        "outputId": "59d37cdc-3d70-4342-bcc5-bccf10612969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Authenticate your notebook environment\n",
        "\n",
        "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n"
      ],
      "metadata": {
        "id": "DY6b2LrP-QFc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9bfFKEXclni",
        "outputId": "e36556b1-f338-4f26-cd1e-1cab432bd746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(unset)\n",
            "Updated property [core/project].\n",
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=rixGbmXlbQTsBM2AwAy3QUUi0BgBh4&prompt=consent&token_usage=remote&access_type=offline&code_challenge=7EL6l9QMY4bjZlIHASHfuTkH111DzOe2IaQ11sz7dRE&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0ASVgi3LaQwlCqRSGvGIDSO9vTlYRGAcM6m68qfNB-wC1IYym1iVTdbu6Ml4jGxXUxSToxg\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n"
          ]
        }
      ],
      "source": [
        "!gcloud config get-value core/project\n",
        "!gcloud config set project genail300\n",
        "\n",
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ],
      "metadata": {
        "id": "aYlOnRLl-T4J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o9yx0OvMcpmQ"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"your-project-id\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWh2w1r3c36x",
        "outputId": "21319195-893e-4933-9296-a1d31a4c7702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.13.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.6.0 (from gradio)\n",
            "  Downloading gradio_client-1.6.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.14)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.5)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.13.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.6.0-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.8/321.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.9.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.45.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.7 ffmpy-0.5.0 gradio-5.13.0 gradio-client-1.6.0 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.9.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.45.2 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6tjOg42csjk"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "import io\n",
        "from typing import Optional, Tuple, Union, List\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image as im\n",
        "import os\n",
        "import gradio as gr\n",
        "from vertexai.preview.vision_models import (\n",
        "    Image,\n",
        "    ImageGenerationModel,\n",
        "    StyleReferenceImage,\n",
        "    SubjectReferenceImage,\n",
        ")\n",
        "from vertexai.generative_models import GenerativeModel, Part\n",
        "from vertexai.generative_models import Image as image_gen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePwK0BItLdTp"
      },
      "source": [
        "### Generate Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vARyXO7neS_y"
      },
      "outputs": [],
      "source": [
        "def pil_to_image(image: im) -> str:\n",
        "    \"\"\"Converts a PIL Image object to a base64 string.\"\"\"\n",
        "    with io.BytesIO() as buffer:\n",
        "        image.save(buffer, format=\"JPEG\")\n",
        "        img_bytes = buffer.getvalue()\n",
        "    return img_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5DNS6Yvgc8d"
      },
      "outputs": [],
      "source": [
        "def resize_image(image_path, base_width=300):\n",
        "  \"\"\"\n",
        "  Resizes an image to the specified base width while maintaining aspect ratio.\n",
        "\n",
        "  Args:\n",
        "    image_path: Path to the image.\n",
        "    base_width: Desired width for the image. Defaults to 300.\n",
        "\n",
        "  Returns:\n",
        "    The resized Image object.\n",
        "  \"\"\"\n",
        "\n",
        "  def calculate_new_dimensions(image_path, base_width):\n",
        "    wpercent = (base_width / float(image_path.size[0]))\n",
        "    hsize = int((float(image_path.size[1]) * float(wpercent)))\n",
        "    return (base_width, hsize)\n",
        "\n",
        "\n",
        "  img = image_path.resize(calculate_new_dimensions(image_path, base_width), im.LANCZOS)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTdt6vv7oCJG"
      },
      "outputs": [],
      "source": [
        "def generate_image(image1_path, image2_path, desc1, desc2, prompt):\n",
        "    \"\"\"Generates an image based on two reference images, their descriptions, and a prompt.\n",
        "\n",
        "    Args:\n",
        "        image1_path: The path to the first reference image file.\n",
        "        image2_path: The path to the second reference image file.\n",
        "        desc1: Description of the first reference image.\n",
        "        desc2: Description of the second reference image.\n",
        "        prompt: The prompt for image generation.\n",
        "\n",
        "    Returns:\n",
        "        The generated image as a PIL Image object.\n",
        "    \"\"\"\n",
        "    print(image1_path, image2_path, desc1, desc2, prompt)\n",
        "\n",
        "    try:\n",
        "        # Load images from file paths\n",
        "        # image1 = im.open(image1_path)\n",
        "        # image2 = im.open(image2_path)\n",
        "\n",
        "\n",
        "        # base_width = 300\n",
        "        # wpercent = (base_width / float(image1_path.size[0]))\n",
        "        # hsize = int((float(image1_path.size[1]) * float(wpercent)))\n",
        "\n",
        "        img1 = resize_image(image1_path)\n",
        "        # wpercent = (base_width / float(image2_path.size[0]))\n",
        "        # hsize = int((float(image2_path.size[1]) * float(wpercent)))\n",
        "\n",
        "        # img2 = image2_path.resize((base_width, hsize),im.LANCZOS)\n",
        "        img2= resize_image(image2_path)\n",
        "        # img3= resize_image(image3_path)\n",
        "\n",
        "        image1= Image(pil_to_image(img1))\n",
        "        image2= Image(pil_to_image(img2))\n",
        "        # image3= Image(pil_to_image(img3))\n",
        "\n",
        "        print(image1, image2)\n",
        "\n",
        "        # Create SubjectReferenceImage objects\n",
        "        ref_image_1 = SubjectReferenceImage(\n",
        "            image=image1,\n",
        "            reference_id=1,\n",
        "            subject_description=desc1,\n",
        "            subject_type=\"product\",\n",
        "        )\n",
        "\n",
        "        ref_image_2 = SubjectReferenceImage(\n",
        "            image=image2,\n",
        "            reference_id=2,\n",
        "            subject_description=desc2,\n",
        "            subject_type=\"product\",\n",
        "        )\n",
        "\n",
        "        # ref_image_3 = SubjectReferenceImage(\n",
        "        #     image=image3,\n",
        "        #     reference_id=3,\n",
        "        #     subject_description=desc3,\n",
        "        #     subject_type=\"product\",\n",
        "        # )\n",
        "\n",
        "\n",
        "        # Generate the image using the customization model\n",
        "        generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-001\")\n",
        "        negative_prompt = \"disfigured, distorted, mutilated, deformed, grotesque, changes to outfit, alterations to clothing, more than 2 hands, more than 2 legs , hallucination\" # Customize as needed\n",
        "\n",
        "        customization_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-capability-001\")\n",
        "        images = customization_model._generate_images(\n",
        "            prompt=prompt,\n",
        "            number_of_images=4,\n",
        "            negative_prompt=negative_prompt,\n",
        "            aspect_ratio=\"1:1\",\n",
        "            reference_images=[ref_image_1, ref_image_2],\n",
        "            safety_filter_level=\"block_few\",\n",
        "            person_generation=\"allow_adult\",\n",
        "\n",
        "        )\n",
        "\n",
        "        # generated_image = images[0]\n",
        "        print(\"Images\", images)\n",
        "        outputs = [this_image._pil_image for this_image in images]\n",
        "        for i in range(4):\n",
        "          if len(outputs) < 4 :\n",
        "            outputs.append(outputs[0])\n",
        "            print(\"length:\" , len(outputs))\n",
        "        print(\"Output\",outputs)\n",
        "        return outputs\n",
        "        # return generated_image._pil_image\n",
        "\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A62QSjFzM0uC"
      },
      "outputs": [],
      "source": [
        "def image_to_bytes(image: im) -> str:\n",
        "    \"\"\"Converts a PIL object to a base64 string.\"\"\"\n",
        "    with io.BytesIO() as buffer:\n",
        "        image.save(buffer, format=\"JPEG\")\n",
        "        img_bytes = buffer.getvalue()\n",
        "    return img_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NRumH7pHbh9"
      },
      "outputs": [],
      "source": [
        "def pil_to_file(image: im, file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Saves a PIL Image object to the specified file path.\n",
        "\n",
        "    Args:\n",
        "        image: The PIL Image object to save.\n",
        "        file_path: The file path where the image will be saved.\n",
        "\n",
        "    Returns:\n",
        "        The file path where the image was saved.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        image.save(file_path, format=\"JPEG\")  # Change format if needed (e.g., PNG)\n",
        "        return file_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving image to file: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "judkGFCDxYPA"
      },
      "source": [
        "### Generate Descriptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IO9vlR0F7vc"
      },
      "outputs": [],
      "source": [
        "def generate_description(image_path):\n",
        "    \"\"\"Generates a description for an image using Gemini.\"\"\"\n",
        "    try:\n",
        "        image = resize_image(image_path)\n",
        "        # new_image_path = pil_to_file(image,\"/content/sample_data/image.jpeg\")\n",
        "        image = image_gen.from_bytes(image_to_bytes(image) )# Convert to Vertex AI Image object\n",
        "        # image = image_to_base64(image)\n",
        "        # image = Image(pil_to_image(image))\n",
        "        print(\" BS \",image)\n",
        "        # print(\"File path\", new_image_path)\n",
        "        model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
        "\n",
        "        response = model.generate_content(\n",
        "    [\n",
        "        image,\n",
        "        \"what is in the image?\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "        # Correct prompt format\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during description generation: {e}\") # Print the detailed error\n",
        "        return \"Error generating description.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV2ynoCdxfzo"
      },
      "source": [
        "### Refine Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3CLGD3DmAb7"
      },
      "outputs": [],
      "source": [
        "def refine_prompt(prompt,desc1,desc2):\n",
        "    \"\"\"Refines the given prompt using Gemini.\"\"\"\n",
        "    try:\n",
        "        model = GenerativeModel(\"gemini-1.5-flash-002\")  # Or a suitable Gemini model\n",
        "        response = model.generate_content(f\"\"\"Rewrite the following prompt for image generation, focusing on creating a concise and effective prompt for a fashion catalog image of a model wearing the outfit. Give only one descriptive paragraph answer:\n",
        "        Prompt: {prompt}\n",
        "        Description 1: {desc1}\n",
        "        Description 2: {desc2}\n",
        "        \"\"\")\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during prompt refinement: {e}\")\n",
        "        return \"Error refining prompt.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUX9slPuxlpm"
      },
      "source": [
        "### Generate Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hgQeneq99bu"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(desc1, desc2):\n",
        "    \"\"\"Generates a prompt for image generation using Gemini, based on two descriptions.\"\"\"\n",
        "    try:\n",
        "        model = GenerativeModel(\"gemini-1.5-flash-002\") # Or any appropriate Gemini model\n",
        "        response = model.generate_content(\n",
        "            f\"\"\"Create one image generation prompt based on these descriptions:\n",
        "            Description 1: {desc1}\n",
        "            Description 2: {desc2}\n",
        "\n",
        "\n",
        "            The prompt should focus on a fashion model  showcasing this particular outfit in different poses and angles highlighting the outfit [1][2].  Be detailed and descriptive, including information about pose, setting, lighting, and overall mood.  Aim for a high-quality, visually appealing image keeping the outfit as described.\"\"\"\n",
        "        )\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during prompt generation: {e}\")\n",
        "        return \"Error generating prompt.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhH1xh7faBYt",
        "outputId": "a45fc58d-6d18-49e5-a7a3-81687ed19bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting markdown2\n",
            "  Downloading markdown2-2.5.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Downloading markdown2-2.5.2-py3-none-any.whl (48 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/48.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: markdown2\n",
            "Successfully installed markdown2-2.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install markdown2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_n36i_Ibfqt"
      },
      "outputs": [],
      "source": [
        "import markdown2\n",
        "def generate_style_and_convert_to_markdown(desc1, desc2, prompt):\n",
        "        try:\n",
        "            model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
        "            response = model.generate_content(\n",
        "                f\"\"\"Suggest different ways to style outfits based on these descriptions and the prompt:\n",
        "                Description 1: {desc1}\n",
        "                Description 2: {desc2}\n",
        "\n",
        "                Prompt: {prompt}\n",
        "\n",
        "                Focus on giving maximum of two providing practical and fashionable styling advice, considering different occasions, accessories, and complementary garments.\"\"\"\n",
        "            )\n",
        "\n",
        "            styling_suggestions_text = response.text.strip()\n",
        "            html_output = markdown2.markdown(styling_suggestions_text)\n",
        "\n",
        "            return html_output, gr.update(visible=True) # Update Markdown section visibility\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred generating styling suggestions: {e}\")\n",
        "            return \"Error generating styling suggestions.\", gr.update(visible=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFsKPMOcxrmU"
      },
      "source": [
        "### Generate Product Description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blagj4IX-t0f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_product_description(image_path):\n",
        "    \"\"\"Generates a product description for an image using Gemini.\"\"\"\n",
        "    try:\n",
        "        image = resize_image(image_path)\n",
        "        # new_image_path = pil_to_file(image,\"/content/sample_data/image.jpeg\")\n",
        "        image = image_gen.from_bytes(image_to_bytes(image) )# Convert to Vertex AI Image object\n",
        "        # image = image_to_base64(image)\n",
        "        # image = Image(pil_to_image(image))\n",
        "\n",
        "        model = GenerativeModel(\"gemini-1.5-flash-002\")  # Or a suitable Gemini model\n",
        "\n",
        "        prompt = (\n",
        "    [\n",
        "        image,\n",
        "        \"\"\"Generate a product description in a table format after analysing the  image:\n",
        "        The table should include these details, If a detail is not present in the image, leave it blank:\n",
        "\n",
        "        | Pattern | |\n",
        "        | Occasion | |\n",
        "        | Fabric | |\n",
        "        | Net Quantity | |\n",
        "        | Colour | |\n",
        "        | Product Category | |\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        ])\n",
        "\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred generating product description: {e}\")\n",
        "        return \"Error generating product description.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMWPvcyP4D-E"
      },
      "source": [
        "###**Campaign** *Generation*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL1hQZoD4V6v"
      },
      "source": [
        "#generate email"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIeTg35l4bSB"
      },
      "outputs": [],
      "source": [
        "def generate_email(prompt):\n",
        "    \"\"\"Generates a fun and sassy email using Gemini based on the image and prompt.\"\"\"\n",
        "    try:\n",
        "        # image = resize_image(image_path)\n",
        "        # # new_image_path = pil_to_file(image,\"/content/sample_data/image.jpeg\")\n",
        "        # # image = image_gen.from_bytes(image_to_bytes(image) )\n",
        "\n",
        "        # # Convert the image to base64\n",
        "        # image = image_to_base64(image)\n",
        "\n",
        "        # print(\"Email Image: \" , image)\n",
        "        model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
        "\n",
        "        # Gemini prompt for email generation\n",
        "        email_prompt = f\"\"\"\n",
        "        Write a fun and sassy email announcing a new collection, based on the uploaded image and the following prompt:\n",
        "        {prompt}\n",
        "\n",
        "\n",
        "\n",
        "        The email should be engaging and reflect current fashion trends. Target a young, fashion-conscious audience.  Use bold text, emojis, and humor where appropriate.  Mention that the new collection is inspired by the attached image.  Include a call to action to visit the website or store.  Keep the email concise.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        response = model.generate_content([email_prompt]) # Pass image too\n",
        "        email_content = response.text.strip()\n",
        "\n",
        "        return email_content\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during email generation: {e}\")\n",
        "        return \"Error generating email.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5Drv1k44cB7"
      },
      "outputs": [],
      "source": [
        "def generate_image_with_text(image_path, prompt):\n",
        "    \"\"\"Generates an image with text overlay using Imagen.\"\"\"\n",
        "\n",
        "\n",
        "    try:\n",
        "\n",
        "        image= Image(pil_to_image(image_path))\n",
        "\n",
        "\n",
        "        print(image)\n",
        "\n",
        "        # Create SubjectReferenceImage objects\n",
        "        ref_image_1 = SubjectReferenceImage(\n",
        "            image=image,\n",
        "            reference_id=1,\n",
        "            subject_type=\"default\",\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # Generate the image using the customization model\n",
        "        generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-001\")\n",
        "        negative_prompt = \"disfigured, distorted, mutilated, deformed, grotesque, changes to outfit, alterations to clothing\" # Customize as needed\n",
        "\n",
        "        customization_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-capability-001\")\n",
        "        images = customization_model._generate_images(\n",
        "            prompt=prompt,\n",
        "            number_of_images=4,\n",
        "            negative_prompt=negative_prompt,\n",
        "            aspect_ratio=\"1:1\",\n",
        "            reference_images=[ref_image_1],\n",
        "            safety_filter_level=\"block_few\",\n",
        "            person_generation=\"allow_adult\",\n",
        "\n",
        "        )\n",
        "\n",
        "        generated_image = images[0]\n",
        "        # print(\"Images\", images)\n",
        "        # outputs = [this_image._pil_image for this_image in images]\n",
        "        # for i in range(4):\n",
        "        #   if len(outputs) < 4 :\n",
        "        #     outputs.append(outputs[0])\n",
        "        #     print(\"length:\" , len(outputs))\n",
        "        # print(\"Output\",outputs)\n",
        "        # return outputs\n",
        "        return generated_image._pil_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during email generation: {e}\")\n",
        "        return \"Error generating email.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8RVVAJfBR1q"
      },
      "source": [
        "## Website Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrpTJHezBW6M"
      },
      "outputs": [],
      "source": [
        "def generate_website(image,prompt):\n",
        "    \"\"\"Generates a fun and sassy email using Gemini based on the image and prompt.\"\"\"\n",
        "    try:\n",
        "        # image = resize_image(image_path)\n",
        "        # # new_image_path = pil_to_file(image,\"/content/sample_data/image.jpeg\")\n",
        "        image = image_gen.from_bytes(image_to_bytes(image) )\n",
        "\n",
        "        # # Convert the image to base64\n",
        "        # image = image_to_base64(image)\n",
        "\n",
        "        # print(\"Email Image: \" , image)\n",
        "        model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
        "\n",
        "        # Gemini prompt for email generation\n",
        "        website_prompt = f\"\"\"\n",
        "        Write a well managed website post announcing a new collection, based on the uploaded image and the following prompt:\n",
        "        {prompt}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        The website should be engaging and reflect current fashion trends. Target a young, fashion-conscious audience.  Use bold text, emojis, and humor where appropriate.  Mention that the new collection is inspired by the attached image.  Include a call to action to visit the website or store.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        response = model.generate_content([image,website_prompt]) # Pass image too\n",
        "        website_content = response.text.strip()\n",
        "\n",
        "        return website_content\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during email generation: {e}\")\n",
        "        return \"Error generating email.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHxVAPtPBRiB"
      },
      "outputs": [],
      "source": [
        "def generate_image_with_text(image_path, prompt):\n",
        "    \"\"\"Generates an image with text overlay using Imagen.\"\"\"\n",
        "\n",
        "\n",
        "    try:\n",
        "\n",
        "        image= Image(pil_to_image(image_path))\n",
        "\n",
        "\n",
        "        print(image)\n",
        "\n",
        "        # Create SubjectReferenceImage objects\n",
        "        ref_image_1 = SubjectReferenceImage(\n",
        "            image=image,\n",
        "            reference_id=1,\n",
        "            subject_type=\"default\",\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # Generate the image using the customization model\n",
        "        generation_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-generate-001\")\n",
        "        negative_prompt = \"disfigured, distorted, mutilated, deformed, grotesque, changes to outfit, alterations to clothing\" # Customize as needed\n",
        "\n",
        "        customization_model = ImageGenerationModel.from_pretrained(\"imagen-3.0-capability-001\")\n",
        "        images = customization_model._generate_images(\n",
        "            prompt=prompt,\n",
        "            number_of_images=4,\n",
        "            negative_prompt=negative_prompt,\n",
        "            aspect_ratio=\"1:1\",\n",
        "            reference_images=[ref_image_1],\n",
        "            safety_filter_level=\"block_few\",\n",
        "            person_generation=\"allow_adult\",\n",
        "\n",
        "        )\n",
        "\n",
        "        generated_image = images[0]\n",
        "        # print(\"Images\", images)\n",
        "        # outputs = [this_image._pil_image for this_image in images]\n",
        "        # for i in range(4):\n",
        "        #   if len(outputs) < 4 :\n",
        "        #     outputs.append(outputs[0])\n",
        "        #     print(\"length:\" , len(outputs))\n",
        "        # print(\"Output\",outputs)\n",
        "        # return outputs\n",
        "        return generated_image._pil_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during email generation: {e}\")\n",
        "        return \"Error generating email.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQfZb4vNRnRf"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "### UI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EvgM60gTyVnH",
        "outputId": "f919a844-f968-4c7b-fdf7-16db688b70d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1ccb3fb4311a73ded3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://1ccb3fb4311a73ded3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " BS  <vertexai.generative_models._generative_models.Image object at 0x7998aacb9550>\n",
            " BS  <vertexai.generative_models._generative_models.Image object at 0x7998a88e7850>\n",
            "<PIL.Image.Image image mode=RGB size=439x698 at 0x7998A7259210> <PIL.Image.Image image mode=RGB size=706x1024 at 0x7998A88EE2D0> That's a lovely image of a woman wearing a light blue, floral-print midi dress. \n",
            "\n",
            "\n",
            "Here's a breakdown of what's visible:\n",
            "\n",
            "* **The Dress:** The dress is the focal point, featuring a light blue base with a smaller, darker blue floral print scattered across it.  The top portion of the dress, from the neckline to just below the bust, has a different, embroidered design in a slightly darker blue shade.  It has three-quarter sleeves and a flared skirt. There's a subtle gold trim at the hem.  The dress appears to be made from a cotton or cotton-blend fabric.\n",
            "\n",
            "* **The Woman:** The woman is young and appears to be of South Asian descent. She's wearing the dress and has on simple, elegant earrings. Her hair is styled neatly.\n",
            "\n",
            "* **The Background:** The background is a plain, light beige or tan, which keeps the focus on the dress and the model.\n",
            "\n",
            "Overall, the image seems to be a product shot, likely from an online clothing store, showcasing the dress. That's a photograph of a woman wearing a light blue, floral-print maxi dress. \n",
            "\n",
            "\n",
            "The dress has a high neckline, three-quarter sleeves, and a flared skirt. The hemline has a subtle gold trim. The woman is shown from the back, and her dark hair is pulled back. She is wearing sandals. The background is a pale beige. \n",
            "<vertexai.vision_models.Image object at 0x7998a735a950> <vertexai.vision_models.Image object at 0x7998a8a0b790>\n",
            "Images ImageGenerationResponse(images=[<vertexai.preview.vision_models.GeneratedImage object at 0x7998a70b9150>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a7239090>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a7239650>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a7249750>])\n",
            "Output [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998B277F650>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A7265910>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A7194310>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A725AD50>]\n",
            "<PIL.Image.Image image mode=RGB size=439x698 at 0x7998A8A0AA10> <PIL.Image.Image image mode=RGB size=706x1024 at 0x7998A7258550> That's a lovely image of a woman wearing a light blue, floral-print midi dress. \n",
            "\n",
            "\n",
            "Here's a breakdown of what's visible:\n",
            "\n",
            "* **The Dress:** The dress is the focal point, featuring a light blue base with a smaller, darker blue floral print scattered across it.  The top portion of the dress, from the neckline to just below the bust, has a different, embroidered design in a slightly darker blue shade.  It has three-quarter sleeves and a flared skirt. There's a subtle gold trim at the hem.  The dress appears to be made from a cotton or cotton-blend fabric.\n",
            "\n",
            "* **The Woman:** The woman is young and appears to be of South Asian descent. She's wearing the dress and has on simple, elegant earrings. Her hair is styled neatly.\n",
            "\n",
            "* **The Background:** The background is a plain, light beige or tan, which keeps the focus on the dress and the model.\n",
            "\n",
            "Overall, the image seems to be a product shot, likely from an online clothing store, showcasing the dress. That's a photograph of a woman wearing a light blue, floral-print maxi dress. \n",
            "\n",
            "\n",
            "The dress has a high neckline, three-quarter sleeves, and a flared skirt. The hemline has a subtle gold trim. The woman is shown from the back, and her dark hair is pulled back. She is wearing sandals. The background is a pale beige. A fashion photoshoot featuring a young South Asian woman showcasing two stunning light blue floral dresses.  The first dress is a midi dress with a light blue base and a smaller, darker blue floral print; the bodice features a darker blue embroidered design. It has three-quarter sleeves, a flared skirt, and subtle gold trim at the hem. The second dress is a maxi dress with a high neckline, three-quarter sleeves, a flared skirt, and subtle gold trim. Both dresses appear to be made of cotton. The model is elegant with simple earrings and her dark hair neatly styled. The background is a consistently pale beige studio backdrop providing a clean and minimalist setting.  The photoshoot will feature multiple shots: one full-body shot of the midi dress from the front, showcasing the embroidery detail,  a three-quarter length shot of the midi dress from a slightly three-quarter angle, highlighting the flow of the skirt, a profile shot of the maxi dress showing the back, showcasing the back details and the sandals, and another full-body shot of the maxi dress from the front.  The lighting is soft and natural, enhancing the colors of the dresses and the model's complexion. The overall mood is sophisticated, elegant, and aspirational, suitable for an online clothing store.  The image style should be high-quality, sharp, and professionally shot, similar to a lookbook or high-fashion magazine spread.  --ar 16:9 --style photorealistic --v 5\n",
            "<vertexai.vision_models.Image object at 0x7998a72587d0> <vertexai.vision_models.Image object at 0x7998a7248650>\n",
            "Images ImageGenerationResponse(images=[<vertexai.preview.vision_models.GeneratedImage object at 0x7998a72483d0>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a7338950>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a733a0d0>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a7338a90>])\n",
            "Output [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A7266790>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A72486D0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A7249A10>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A70BDA90>]\n",
            " BS  <vertexai.generative_models._generative_models.Image object at 0x7998a70beb10>\n",
            " BS  <vertexai.generative_models._generative_models.Image object at 0x7998a9016bd0>\n",
            "<PIL.Image.Image image mode=RGB size=260x280 at 0x7998B09E1390> <PIL.Image.Image image mode=RGB size=612x475 at 0x7998A75D15D0> That's a mustard yellow kurta (or tunic) hanging on a white hanger against a gray background.  The kurta is a simple, straight-cut design with three-quarter sleeves and a placket of small buttons down the front.  The sleeves have a subtle white trim detail.  It appears to be made from a lightweight, possibly linen-like fabric. That's a close-up photo of a young woman with tan skin and long brown hair with lighter highlights.  She's smiling gently and has one hand lightly touching her face.  The background is a plain, light gray or white.  The image is likely a beauty shot, focusing on her healthy-looking skin and hair. A fashion photoshoot showcasing a mustard yellow linen kurta with subtle white sleeve trim and a placket of small buttons. The kurta, hanging on a white hanger in a previous shot [1], is now worn by a young woman with tan skin and long brown hair with subtle highlights [2].  She is posed in three distinct shots against a minimalist light gray backdrop:  (1) A full-length shot, standing gracefully with one hand gently resting on her hip, showcasing the kurta's flow and length. (2) A close-up shot focusing on the kurta's details – the texture of the fabric, the white trim, and the button placket – with her hand lightly touching her face, mirroring the original beauty shot [2]. (3) A three-quarter shot, showcasing the kurta’s movement as she subtly turns, highlighting the three-quarter sleeves.  Soft, natural light illuminates her face and the kurta, creating a warm and inviting mood. The overall aesthetic should be clean, modern, and minimalist, focusing on the beauty of the garment and the model's natural elegance.  High-quality, detailed rendering with realistic fabric textures and skin tones is desired.  Style: Fashion photography, editorial.\n",
            "<vertexai.vision_models.Image object at 0x7998a70aefd0> <vertexai.vision_models.Image object at 0x7998a70af190>\n",
            "Images ImageGenerationResponse(images=[<vertexai.preview.vision_models.GeneratedImage object at 0x7998a742c210>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a71820d0>, <vertexai.preview.vision_models.GeneratedImage object at 0x7998a7180c50>])\n",
            "length: 4\n",
            "Output [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A8721990>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A9016F10>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A7183090>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=1024x1024 at 0x7998A8721990>]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "with gr.Blocks() as iface:\n",
        "    iface.title = \"Soch Apparels\"\n",
        "\n",
        "    image_url = \"https://images.yourstory.com/cs/images/companies/Soch-1634551344036.jpg?fm=auto&ar=1%3A1&mode=fill&fill=solid&fill-color=fff&format=auto&w=384&q=75\"\n",
        "\n",
        "    gr.HTML(f\"\"\"\n",
        "    <div style=\"display: flex; justify-content: center; padding-top: 0;\">\n",
        "      <img src=\"{image_url}\" alt=\"Soch\" style=\"width: 300px; height: auto;\"\">\n",
        "    </div>\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            image1_input = gr.Image(type=\"pil\", label=\"Reference Image 1\",width=\"200px\")\n",
        "            desc1_input = gr.Textbox(label=\"Description\")\n",
        "            gemini_button1 = gr.Button(\"Generate Description\")\n",
        "            gemini_button1.click(generate_description, inputs=image1_input, outputs=desc1_input)\n",
        "\n",
        "        with gr.Column():\n",
        "            image2_input = gr.Image(type=\"pil\", label=\"Reference Image 2\",width=\"200px\")\n",
        "            desc2_input = gr.Textbox(label=\"Description\")\n",
        "            gemini_button2 = gr.Button(\"Generate Description\")\n",
        "            gemini_button2.click(generate_description, inputs=image2_input, outputs=desc2_input)\n",
        "\n",
        "        # with gr.Column():\n",
        "        #     image3_input = gr.Image(type=\"pil\", label=\"Reference Image 3\",width=\"200px\")\n",
        "        #     desc3_input = gr.Textbox(label=\"Description\")\n",
        "        #     gemini_button3 = gr.Button(\"Generate Description\")\n",
        "        #     gemini_button3.click(generate_description, inputs=image3_input, outputs=desc3_input)\n",
        "\n",
        "\n",
        "\n",
        "    prompt_input = gr.Textbox(label=\"Prompt\")\n",
        "    refine_button = gr.Button(\"Refine Prompt\")  # New button for prompt refinement\n",
        "    generate_prompt_button = gr.Button(\"Generate Prompt\") # New button\n",
        "    generate_image_button = gr.Button(\"Generate Image\")  # Renamed for clarity\n",
        "    generated_image_output = [gr.Image(type=\"pil\", label=\"Generated Image\") for _ in range(4)]\n",
        "\n",
        "\n",
        "    # Styling suggestions\n",
        "    styling_suggestions = gr.Textbox(label=\"Styling Suggestions\", lines=5, visible=False)\n",
        "    style_button = gr.Button(\"Product Styling\", visible=False)\n",
        "    styling_suggestions_markdown = gr.HTML(\"\"\"Styling Suggestions (Markdown)\"\"\", visible=False)  # Initially hidden\n",
        "\n",
        "    # Product Description section (NEW)\n",
        "    gr.HTML(f\"\"\"\n",
        "    <div>\n",
        "      <h2 style=\"text-align: center;\">Product Description</h2>\n",
        "    </div>\n",
        "    \"\"\")\n",
        "    product_input=gr.Image(type=\"pil\", label=\"Reference Image 2\",width=\"200px\")\n",
        "    # product_description_output = gr.Textbox(label=\"Product Description\", lines=10, visible=False)  # More lines for the table\n",
        "    generate_description_button = gr.Button(\"Generate Product Description\")  # New button\n",
        "    product_description_output = gr.Textbox(label=\"Product Description\", lines=10)\n",
        "\n",
        "\n",
        "    # style_button = gr.Button(\"Change to Markdown\", visible=False) # Initially hidden\n",
        "        # styling_suggestions = gr.HTML(\"\"\"<p>Styling Suggestions</p>\"\"\")\n",
        "\n",
        "\n",
        "    refine_button.click(refine_prompt, inputs=[prompt_input,desc1_input, desc2_input], outputs=prompt_input)\n",
        "\n",
        "\n",
        "    generate_prompt_button.click(\n",
        "        generate_prompt,\n",
        "        inputs=[desc1_input, desc2_input],\n",
        "        outputs=prompt_input,\n",
        "    )\n",
        "\n",
        "    def show_generated_images(*args):\n",
        "        # Function to generate images and make them visible\n",
        "        images = generate_image(*args)\n",
        "        return images + [gr.update(visible=True) for _ in generated_image_outputs]\n",
        "\n",
        "    generate_image_button.click(  # Click handler for image generation\n",
        "        generate_image,\n",
        "        inputs=[image1_input, image2_input, desc1_input, desc2_input,  prompt_input],\n",
        "        outputs=generated_image_output,\n",
        "    ).then( #makes the convert to markdown button visible\n",
        "        fn=lambda x: gr.update(visible=True),\n",
        "        inputs=styling_suggestions,\n",
        "        outputs=style_button,\n",
        "    )\n",
        "\n",
        "    style_button.click(\n",
        "        generate_style_and_convert_to_markdown,\n",
        "        inputs=[desc1_input, desc2_input, prompt_input],\n",
        "        outputs=[styling_suggestions_markdown, styling_suggestions_markdown ],\n",
        "    )\n",
        "\n",
        "    generate_description_button.click(\n",
        "            generate_product_description,\n",
        "            inputs=product_input,  # Use the first generated image\n",
        "            outputs=product_description_output,\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "     ## Campaign creation\n",
        "    email_prompt_section_visible = False\n",
        "    website_prompt_section_visible = False\n",
        "    social_media_prompt_section_visible = False\n",
        "\n",
        "      # New section for content generation buttons\n",
        "    email_button = gr.Button(\"Generate Email\")\n",
        "\n",
        "\n",
        "    # Email prompt section\n",
        "    with gr.Row(visible=False) as email_prompt_section:\n",
        "      with gr.Column():\n",
        "        image_input = gr.Image(label=\"Upload an Image\", type=\"pil\")\n",
        "        with gr.Column():\n",
        "            prompt_input = gr.Textbox(label=\"Enter Prompt for Email\")\n",
        "            prompt_image_email_imput = gr.Textbox(label=\"Enter Prompt for Image\")\n",
        "        with gr.Column():\n",
        "          generate_button = gr.Button(\"Generate Email\")\n",
        "          generate_image_button = gr.Button(\"Generate Image \")\n",
        "      with gr.Column():\n",
        "        email_output = gr.Textbox(label=\"Generated Email\", lines=10)\n",
        "        generated_image_output = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
        "\n",
        "\n",
        "    # Function to make the email prompt section visible\n",
        "    def show_email_prompt():\n",
        "        return gr.update(visible=True)\n",
        "\n",
        "    # Link the email_generate_button to display the prompt section\n",
        "    email_button.click(\n",
        "        show_email_prompt,\n",
        "        inputs=[],\n",
        "        outputs=email_prompt_section\n",
        "    )\n",
        "\n",
        "    # Link the generate button to the generate_email function\n",
        "    generate_button.click(\n",
        "        generate_email,\n",
        "        inputs=[prompt_input],\n",
        "        outputs=email_output\n",
        "    )\n",
        "\n",
        "    generate_image_button.click(\n",
        "        generate_image_with_text,\n",
        "        inputs=[image_input,prompt_image_email_imput],\n",
        "        outputs=generated_image_output\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    #website section\n",
        "\n",
        "    website_button = gr.Button(\"Generate Website Campaign\")\n",
        "    # social_media_button = gr.Button(\"Generate Social Media Campaign\")\n",
        "\n",
        "    # Website prompt section\n",
        "    with gr.Row(visible=False) as website_prompt_section:\n",
        "        with gr.Column():\n",
        "          image_input = gr.Image(label=\"Upload an Image\", type=\"pil\")\n",
        "          with gr.Column():\n",
        "            prompt_input = gr.Textbox(label=\"Enter Prompt for Website\")\n",
        "            prompt_image_website_input = gr.Textbox(label=\"Enter Prompt for Image\")\n",
        "          with gr.Column():\n",
        "            generate_button = gr.Button(\"Generate\")\n",
        "            generate_image_button = gr.Button(\"Generate Image\")\n",
        "        with gr.Column():\n",
        "          website_output = gr.Textbox(label=\"Generated Website\")\n",
        "          generated_image_output = gr.Image(label=\"Generated Image\", type=\"pil\")\n",
        "\n",
        "\n",
        "    # Function to make the website prompt section visible\n",
        "    def show_website_prompt():\n",
        "        return gr.update(visible=True)\n",
        "\n",
        "\n",
        "    # Link the website_generate_button to display the prompt section\n",
        "    website_button.click(\n",
        "        show_website_prompt,\n",
        "        inputs=[],\n",
        "        outputs=website_prompt_section\n",
        "    )\n",
        "\n",
        "    # Link the generate button to the generate_email function\n",
        "    generate_button.click(\n",
        "        generate_website,\n",
        "        inputs=[image_input, prompt_input],\n",
        "        outputs=website_output\n",
        "    )\n",
        "\n",
        "    generate_image_button.click(\n",
        "        generate_image_with_text,\n",
        "        inputs=[image_input,prompt_image_website_input],\n",
        "        outputs=generated_image_output\n",
        "    )\n",
        "\n",
        "\n",
        "    # website_button.click(\n",
        "    #     generate_website_campaign,\n",
        "    #     inputs=[generated_image_output[0], desc1_input, desc2_input, prompt_input],  # Pass necessary inputs\n",
        "    #     outputs=website_output,\n",
        "    # )\n",
        "\n",
        "\n",
        "    # social_media_button.click(\n",
        "    #     generate_social_media_campaign,\n",
        "    #     inputs=[generated_image_output[0], desc1_input, desc2_input, prompt_input],  # Pass necessary inputs\n",
        "    #     outputs=social_media_output,\n",
        "    # )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "iface.launch(debug=True, show_error=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzoqqaV9r9b0"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}